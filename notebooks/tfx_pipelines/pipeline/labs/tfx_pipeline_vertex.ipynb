{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Continuous training with TFX and Vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1. Containerize your TFX code into a pipeline package using Cloud Build.\n",
    "1. Use the TFX CLI to compile a TFX pipeline.\n",
    "1. Deploy a TFX pipeline version to run on Vertex Pipelines using the Vertex Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate lab package version installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.6.5\n",
      "TFX version: 1.4.0\n",
      "KFP version: 1.8.10\n",
      "aiplatform: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tensorflow as tf; print(f'TF version: {tf.__version__}')\"\n",
    "!python -c \"import tfx; print(f'TFX version: {tfx.__version__}')\"\n",
    "!python -c \"import kfp; print(f'KFP version: {kfp.__version__}')\"\n",
    "print(f\"aiplatform: {vertex_ai.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: this lab was built and tested with the following package versions:\n",
    "\n",
    "`TF version: 2.6.2`\n",
    "\n",
    "`TFX version: 1.4.0` \n",
    "\n",
    "`KFP version: 1.8.1`\n",
    "\n",
    "`aiplatform: 1.7.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: example TFX pipeline design pattern for Vertex\n",
    "The pipeline source code can be found in the `pipeline_vertex` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/asl-ml-immersion/notebooks/tfx_pipelines/pipeline/labs/pipeline_vertex\n"
     ]
    }
   ],
   "source": [
    "%cd pipeline_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 52\n",
      "drwxr-xr-x 4 jupyter jupyter 4096 Nov 17 14:08 .\n",
      "drwxr-xr-x 4 jupyter jupyter 4096 Nov 17 14:09 ..\n",
      "drwxr-xr-x 2 jupyter jupyter 4096 Nov 17 14:37 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 jupyter jupyter  131 Nov 14 10:05 Dockerfile\n",
      "-rw-r--r-- 1 jupyter jupyter 1972 Nov 14 10:05 config.py\n",
      "-rw-r--r-- 1 jupyter jupyter 1090 Nov 14 10:05 features.py\n",
      "-rw-r--r-- 1 jupyter jupyter 6482 Nov 14 10:05 model.py\n",
      "-rw-r--r-- 1 jupyter jupyter 5657 Nov 14 10:05 pipeline.py\n",
      "-rw-r--r-- 1 jupyter jupyter 2182 Nov 14 10:05 preprocessing.py\n",
      "-rw-r--r-- 1 jupyter jupyter 1322 Nov 14 10:05 runner.py\n",
      "drwxr-xr-x 2 jupyter jupyter 4096 Nov 14 10:05 schema\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `config.py` module configures the default values for the environment specific settings and the default values for the pipeline runtime parameters. \n",
    "The default values can be overwritten at compile time by providing the updated values in a set of environment variables. You will set custom environment variables later on this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipeline.py` module contains the TFX DSL defining the workflow implemented by the pipeline.\n",
    "\n",
    "The `preprocessing.py` module implements the data preprocessing logic  the `Transform` component.\n",
    "\n",
    "The `model.py` module implements the TensorFlow model code and training logic for the `Trainer` component.\n",
    "\n",
    "The `runner.py` module configures and executes `KubeflowV2DagRunner`. At compile time, the `KubeflowDagRunner.run()` method converts the TFX DSL into the pipeline package into a JSON format for execution on Vertex.\n",
    "\n",
    "The `features.py` module contains feature definitions common across `preprocessing.py` and `model.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: build your pipeline with the TFX CLI\n",
    "\n",
    "You will use TFX CLI to compile and deploy the pipeline. As explained in the previous section, the environment specific settings can be provided through a set of environment variables and embedded into the pipeline package at compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure your environment resource settings\n",
    "\n",
    "Update  the below constants  with the settings reflecting your lab environment. \n",
    "\n",
    "- `REGION` - the compute region for AI Platform Training, Vizier, and Prediction.\n",
    "- `ARTIFACT_STORE` - An existing GCS bucket. You can use any bucket, but we will use here the bucket with the same name as the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set your environment resource settings here for GCP_REGION, ARTIFACT_STORE_URI, ENDPOINT, and CUSTOM_SERVICE_ACCOUNT.\n",
    "REGION = \"us-central1\"\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REGION=us-central1\n",
      "env: ARTIFACT_STORE=gs://qwiklabs-asl-01-579c20dd4e24\n",
      "env: PROJECT_ID=qwiklabs-asl-01-579c20dd4e24\n"
     ]
    }
   ],
   "source": [
    "# Set your resource settings as environment variables. These override the default values in pipeline/config.py.\n",
    "%env REGION={REGION}\n",
    "%env ARTIFACT_STORE={ARTIFACT_STORE}\n",
    "%env PROJECT_ID={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-asl-01-579c20dd4e24/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set the compile time settings to first create a pipeline version without hyperparameter tuning\n",
    "\n",
    "Default pipeline runtime environment values are configured in the pipeline folder `config.py`. You will set their values directly below:\n",
    "\n",
    "* `PIPELINE_NAME` - the pipeline's globally unique name.\n",
    "\n",
    "* `DATA_ROOT_URI` - the URI for the raw lab dataset `gs://{PROJECT_ID}/data/tfxcovertype`.\n",
    "\n",
    "* `TFX_IMAGE_URI` - the image name of your pipeline container that will be used to execute each of your tfx components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"tfxcovertype\"\n",
    "DATA_ROOT_URI = f\"gs://{PROJECT_ID}/data/tfxcovertype\"\n",
    "TFX_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{PIPELINE_NAME}\"\n",
    "PIPELINE_JSON = f\"{PIPELINE_NAME}.json\"\n",
    "\n",
    "TRAIN_STEPS = 10\n",
    "EVAL_STEPS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PIPELINE_NAME=tfxcovertype\n",
      "env: DATA_ROOT_URI=gs://qwiklabs-asl-01-579c20dd4e24/data/tfxcovertype\n",
      "env: TFX_IMAGE_URI=gcr.io/qwiklabs-asl-01-579c20dd4e24/tfxcovertype\n",
      "env: PIPELINE_JSON=tfxcovertype.json\n",
      "env: TRAIN_STEPS=10\n",
      "env: EVAL_STEPS=5\n"
     ]
    }
   ],
   "source": [
    "%env PIPELINE_NAME={PIPELINE_NAME}\n",
    "%env DATA_ROOT_URI={DATA_ROOT_URI}\n",
    "%env TFX_IMAGE_URI={TFX_IMAGE_URI}\n",
    "%env PIPELINE_JSON={PIPELINE_JSON}\n",
    "%env TRAIN_STEPS={TRAIN_STEPS}\n",
    "%env EVAL_STEPS={EVAL_STEPS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us populate the data bucket at `DATA_ROOT_URI`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../../../data/dataset.csv [Content-Type=text/csv]...\n",
      "- [1 files][  5.3 MiB/  5.3 MiB]                                                \n",
      "Operation completed over 1 objects/5.3 MiB.                                      \n",
      "gs://qwiklabs-asl-01-579c20dd4e24/data/tfxcovertype/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp  ../../../data/* $DATA_ROOT_URI/dataset.csv\n",
    "!gsutil ls $DATA_ROOT_URI/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build and push the TFX container image described in the `Dockerfile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 15 file(s) totalling 39.7 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://qwiklabs-asl-01-579c20dd4e24_cloudbuild/source/1668696554.129948-0ab50c6c1a5f4c3f91f62dc959625d37.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-asl-01-579c20dd4e24/locations/global/builds/50ccc38a-7852-416e-b039-e6e215e00740].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/50ccc38a-7852-416e-b039-e6e215e00740?project=296524281444 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"50ccc38a-7852-416e-b039-e6e215e00740\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-asl-01-579c20dd4e24_cloudbuild/source/1668696554.129948-0ab50c6c1a5f4c3f91f62dc959625d37.tgz#1668696554451689\n",
      "Copying gs://qwiklabs-asl-01-579c20dd4e24_cloudbuild/source/1668696554.129948-0ab50c6c1a5f4c3f91f62dc959625d37.tgz#1668696554451689...\n",
      "/ [1 files][  8.0 KiB/  8.0 KiB]                                                \n",
      "Operation completed over 1 objects/8.0 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  54.78kB\n",
      "Step 1/4 : FROM gcr.io/tfx-oss-public/tfx:1.4.0\n",
      "1.4.0: Pulling from tfx-oss-public/tfx\n",
      "e4ca327ec0e7: Pulling fs layer\n",
      "0fa9fc055636: Pulling fs layer\n",
      "448bb2d7fba5: Pulling fs layer\n",
      "a084e2627368: Pulling fs layer\n",
      "de932d3a14d8: Pulling fs layer\n",
      "ebe7db8e97e0: Pulling fs layer\n",
      "66fef8aabad3: Pulling fs layer\n",
      "9696f5331161: Pulling fs layer\n",
      "7799e2177407: Pulling fs layer\n",
      "56d35ebee226: Pulling fs layer\n",
      "f23d5847df7e: Pulling fs layer\n",
      "85729b3aa914: Pulling fs layer\n",
      "27594cd25c9b: Pulling fs layer\n",
      "420dbd17143e: Pulling fs layer\n",
      "71797a45a0de: Pulling fs layer\n",
      "b073ad8b8421: Pulling fs layer\n",
      "4b7516634a4b: Pulling fs layer\n",
      "434af55afd20: Pulling fs layer\n",
      "85d42009e725: Pulling fs layer\n",
      "6d895d7b587a: Pulling fs layer\n",
      "9ff76d709282: Pulling fs layer\n",
      "4160ec915caf: Pulling fs layer\n",
      "eb84f1e37919: Pulling fs layer\n",
      "a616daa88ca5: Pulling fs layer\n",
      "99b8f7435830: Pulling fs layer\n",
      "1e2f495eab09: Pulling fs layer\n",
      "d880b09bf9ec: Pulling fs layer\n",
      "403fe241a00b: Pulling fs layer\n",
      "ca533ed5e802: Pulling fs layer\n",
      "9d118b4c5fa6: Pulling fs layer\n",
      "388915f48178: Pulling fs layer\n",
      "ddeefb06ab95: Pulling fs layer\n",
      "62d0755e4559: Pulling fs layer\n",
      "58a229d727c0: Pulling fs layer\n",
      "c4606a99c9de: Pulling fs layer\n",
      "a084e2627368: Waiting\n",
      "de932d3a14d8: Waiting\n",
      "ebe7db8e97e0: Waiting\n",
      "66fef8aabad3: Waiting\n",
      "9696f5331161: Waiting\n",
      "7799e2177407: Waiting\n",
      "56d35ebee226: Waiting\n",
      "f23d5847df7e: Waiting\n",
      "85729b3aa914: Waiting\n",
      "27594cd25c9b: Waiting\n",
      "420dbd17143e: Waiting\n",
      "71797a45a0de: Waiting\n",
      "b073ad8b8421: Waiting\n",
      "4b7516634a4b: Waiting\n",
      "434af55afd20: Waiting\n",
      "85d42009e725: Waiting\n",
      "6d895d7b587a: Waiting\n",
      "9ff76d709282: Waiting\n",
      "4160ec915caf: Waiting\n",
      "eb84f1e37919: Waiting\n",
      "a616daa88ca5: Waiting\n",
      "99b8f7435830: Waiting\n",
      "1e2f495eab09: Waiting\n",
      "d880b09bf9ec: Waiting\n",
      "403fe241a00b: Waiting\n",
      "ca533ed5e802: Waiting\n",
      "9d118b4c5fa6: Waiting\n",
      "388915f48178: Waiting\n",
      "ddeefb06ab95: Waiting\n",
      "62d0755e4559: Waiting\n",
      "58a229d727c0: Waiting\n",
      "c4606a99c9de: Waiting\n",
      "448bb2d7fba5: Verifying Checksum\n",
      "448bb2d7fba5: Download complete\n",
      "e4ca327ec0e7: Verifying Checksum\n",
      "e4ca327ec0e7: Download complete\n",
      "0fa9fc055636: Verifying Checksum\n",
      "0fa9fc055636: Download complete\n",
      "a084e2627368: Verifying Checksum\n",
      "a084e2627368: Download complete\n",
      "de932d3a14d8: Verifying Checksum\n",
      "de932d3a14d8: Download complete\n",
      "66fef8aabad3: Verifying Checksum\n",
      "66fef8aabad3: Download complete\n",
      "7799e2177407: Verifying Checksum\n",
      "7799e2177407: Download complete\n",
      "e4ca327ec0e7: Pull complete\n",
      "0fa9fc055636: Pull complete\n",
      "448bb2d7fba5: Pull complete\n",
      "a084e2627368: Pull complete\n",
      "de932d3a14d8: Pull complete\n",
      "9696f5331161: Verifying Checksum\n",
      "9696f5331161: Download complete\n",
      "f23d5847df7e: Verifying Checksum\n",
      "f23d5847df7e: Download complete\n",
      "56d35ebee226: Verifying Checksum\n",
      "56d35ebee226: Download complete\n",
      "27594cd25c9b: Verifying Checksum\n",
      "27594cd25c9b: Download complete\n",
      "85729b3aa914: Verifying Checksum\n",
      "85729b3aa914: Download complete\n",
      "71797a45a0de: Verifying Checksum\n",
      "71797a45a0de: Download complete\n",
      "420dbd17143e: Verifying Checksum\n",
      "420dbd17143e: Download complete\n",
      "4b7516634a4b: Verifying Checksum\n",
      "4b7516634a4b: Download complete\n",
      "ebe7db8e97e0: Verifying Checksum\n",
      "ebe7db8e97e0: Download complete\n",
      "434af55afd20: Verifying Checksum\n",
      "434af55afd20: Download complete\n",
      "85d42009e725: Verifying Checksum\n",
      "85d42009e725: Download complete\n",
      "6d895d7b587a: Verifying Checksum\n",
      "6d895d7b587a: Download complete\n",
      "9ff76d709282: Verifying Checksum\n",
      "9ff76d709282: Download complete\n",
      "4160ec915caf: Verifying Checksum\n",
      "4160ec915caf: Download complete\n",
      "eb84f1e37919: Verifying Checksum\n",
      "eb84f1e37919: Download complete\n",
      "a616daa88ca5: Verifying Checksum\n",
      "a616daa88ca5: Download complete\n",
      "99b8f7435830: Verifying Checksum\n",
      "99b8f7435830: Download complete\n",
      "b073ad8b8421: Verifying Checksum\n",
      "b073ad8b8421: Download complete\n",
      "1e2f495eab09: Verifying Checksum\n",
      "1e2f495eab09: Download complete\n",
      "403fe241a00b: Verifying Checksum\n",
      "403fe241a00b: Download complete\n",
      "9d118b4c5fa6: Verifying Checksum\n",
      "9d118b4c5fa6: Download complete\n",
      "388915f48178: Verifying Checksum\n",
      "388915f48178: Download complete\n",
      "ddeefb06ab95: Verifying Checksum\n",
      "ddeefb06ab95: Download complete\n",
      "62d0755e4559: Verifying Checksum\n",
      "62d0755e4559: Download complete\n",
      "58a229d727c0: Verifying Checksum\n",
      "58a229d727c0: Download complete\n",
      "ca533ed5e802: Verifying Checksum\n",
      "ca533ed5e802: Download complete\n",
      "d880b09bf9ec: Verifying Checksum\n",
      "d880b09bf9ec: Download complete\n",
      "c4606a99c9de: Verifying Checksum\n",
      "c4606a99c9de: Download complete\n",
      "ebe7db8e97e0: Pull complete\n",
      "66fef8aabad3: Pull complete\n",
      "9696f5331161: Pull complete\n",
      "7799e2177407: Pull complete\n",
      "56d35ebee226: Pull complete\n",
      "f23d5847df7e: Pull complete\n",
      "85729b3aa914: Pull complete\n",
      "27594cd25c9b: Pull complete\n",
      "420dbd17143e: Pull complete\n",
      "71797a45a0de: Pull complete\n",
      "b073ad8b8421: Pull complete\n",
      "4b7516634a4b: Pull complete\n",
      "434af55afd20: Pull complete\n",
      "85d42009e725: Pull complete\n",
      "6d895d7b587a: Pull complete\n",
      "9ff76d709282: Pull complete\n",
      "4160ec915caf: Pull complete\n",
      "eb84f1e37919: Pull complete\n",
      "a616daa88ca5: Pull complete\n",
      "99b8f7435830: Pull complete\n",
      "1e2f495eab09: Pull complete\n",
      "d880b09bf9ec: Pull complete\n",
      "403fe241a00b: Pull complete\n",
      "ca533ed5e802: Pull complete\n",
      "9d118b4c5fa6: Pull complete\n",
      "388915f48178: Pull complete\n",
      "ddeefb06ab95: Pull complete\n",
      "62d0755e4559: Pull complete\n",
      "58a229d727c0: Pull complete\n",
      "c4606a99c9de: Pull complete\n",
      "Digest: sha256:1c90d7c7df1d78147013ae8d0377b1496b211391d740b88da6d9892946c30fb1\n",
      "Status: Downloaded newer image for gcr.io/tfx-oss-public/tfx:1.4.0\n",
      " ---> 8badc9bc28b6\n",
      "Step 2/4 : RUN pip install -U pip\n",
      " ---> Running in 8c0c0f4aafad\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.3.1\n",
      "    Uninstalling pip-21.3.1:\n",
      "      Successfully uninstalled pip-21.3.1\n",
      "Successfully installed pip-22.3.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 8c0c0f4aafad\n",
      " ---> bffd2432b952\n",
      "Step 3/4 : RUN pip install google-cloud-aiplatform==1.7.1 kfp==1.8.1\n",
      " ---> Running in 282a76d81009\n",
      "Collecting google-cloud-aiplatform==1.7.1\n",
      "  Downloading google_cloud_aiplatform-1.7.1-py2.py3-none-any.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 28.4 MB/s eta 0:00:00\n",
      "Collecting kfp==1.8.1\n",
      "  Downloading kfp-1.8.1.tar.gz (248 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 248.5/248.5 kB 30.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (2.30.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (1.31.4)\n",
      "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (1.42.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (20.9)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (1.19.7)\n",
      "Collecting absl-py<=0.11,>=0.9\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.8/127.8 kB 19.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (5.4.1)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (12.0.1)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (1.12.8)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (1.35.0)\n",
      "Collecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 9.2 MB/s eta 0:00:00\n",
      "Collecting cloudpickle<2,>=1.3.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.1/58.1 kB 10.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jsonschema<4,>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 kB 9.2 MB/s eta 0:00:00\n",
      "Collecting tabulate<1,>=0.8.6\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: click<8,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (7.1.2)\n",
      "Collecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.10 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (0.1.13)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.7/87.7 kB 14.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (3.19.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (1.8.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<=0.11,>=0.9->kfp==1.8.1) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp==1.8.1) (1.12.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp==1.8.1) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2021.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (58.5.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2.25.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.53.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.41.1)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.1) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.1) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.1) (0.19.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.1) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.1) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.1) (4.2.4)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (2.8.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (1.7.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (2.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.1) (4.8.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.1) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.1) (20.3.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.1) (1.26.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.1) (2021.10.8)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp==1.8.1) (1.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp==1.8.1) (0.57.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform==1.7.1) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from pydantic<2,>=1.8.2->kfp==1.8.1) (3.7.4.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp==1.8.1) (0.37.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (1.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp==1.8.1) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (4.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp==1.8.1) (3.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp==1.8.1) (3.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (2.20)\n",
      "Building wheels for collected packages: kfp, fire, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.8.1-py3-none-any.whl size=345340 sha256=d6b8a9e90625838e341526e4ee839c6d960db6344174fbcbe944606c2609711c\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/f5/b5/ec52eb75a8cbf994e7b2c8405e17f5175460e10b7c2cbb44cc\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=38f8c191023ff4d35d94139aa078ddd91e36f90e110164d32173749e93fb7037\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/21/65/2ac62db55efa6e6edfad09f4e315aa82a35ab138f51e784fb1\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99715 sha256=479db94c81985600fece01f5d88fd2a8b47a0dd409f733973a2713782ffa2c59\n",
      "  Stored in directory: /root/.cache/pip/wheels/64/f0/9d/dcf844b38d247b944657d0b9e8d55b76baef9bfdeb680e4596\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22302 sha256=a4bd0be46a385148c6dd7060728e793a54f370201c23af9127c2957b7715e74f\n",
      "  Stored in directory: /root/.cache/pip/wheels/5a/4e/89/a4493443c6aadb8a38e9709610efc3bfafaea3a4108df4c112\n",
      "Successfully built kfp fire kfp-server-api strip-hints\n",
      "Installing collected packages: tabulate, strip-hints, fire, docstring-parser, Deprecated, cloudpickle, absl-py, requests-toolbelt, kfp-server-api, jsonschema, kfp, google-cloud-aiplatform\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.0.0\n",
      "    Uninstalling cloudpickle-2.0.0:\n",
      "      Successfully uninstalled cloudpickle-2.0.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.1.2\n",
      "    Uninstalling jsonschema-4.1.2:\n",
      "      Successfully uninstalled jsonschema-4.1.2\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.6.2\n",
      "    Uninstalling google-cloud-aiplatform-1.6.2:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.6.2\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.18.0 requires tensorflow-io-gcs-filesystem==0.18.0, which is not installed.\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\n",
      "tensorflow-io 0.18.0 requires tensorflow<2.6.0,>=2.5.0, but you have tensorflow 2.6.2 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.13 absl-py-0.11.0 cloudpickle-1.6.0 docstring-parser-0.15 fire-0.4.0 google-cloud-aiplatform-1.7.1 jsonschema-3.2.0 kfp-1.8.1 kfp-server-api-1.8.5 requests-toolbelt-0.10.1 strip-hints-0.1.10 tabulate-0.9.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 282a76d81009\n",
      " ---> afaf7333416c\n",
      "Step 4/4 : COPY . ./\n",
      " ---> 919329d2f5de\n",
      "Successfully built 919329d2f5de\n",
      "Successfully tagged gcr.io/qwiklabs-asl-01-579c20dd4e24/tfxcovertype:latest\n",
      "PUSH\n",
      "Pushing gcr.io/qwiklabs-asl-01-579c20dd4e24/tfxcovertype\n",
      "The push refers to repository [gcr.io/qwiklabs-asl-01-579c20dd4e24/tfxcovertype]\n",
      "697060c05ee9: Preparing\n",
      "f6ae1a92434a: Preparing\n",
      "29f0c0ff9749: Preparing\n",
      "47eadc53848d: Preparing\n",
      "360afeadb83c: Preparing\n",
      "610c8c70c225: Preparing\n",
      "11aaa1ad9bbe: Preparing\n",
      "c1540b4fd089: Preparing\n",
      "5be20e773bf8: Preparing\n",
      "f0aed3b553c7: Preparing\n",
      "e55c134eccb1: Preparing\n",
      "b3e660ff020a: Preparing\n",
      "1795fd5db4de: Preparing\n",
      "dad41956ce77: Preparing\n",
      "ab61683fbd20: Preparing\n",
      "117941aa2d3f: Preparing\n",
      "3a4c764c9a45: Preparing\n",
      "34db85e87fb0: Preparing\n",
      "782857218c62: Preparing\n",
      "195f2f019955: Preparing\n",
      "9546e4c87db8: Preparing\n",
      "78613865172b: Preparing\n",
      "97676aba1403: Preparing\n",
      "0fb4d6eba0b6: Preparing\n",
      "e8b9f9e4195c: Preparing\n",
      "eb1f25078652: Preparing\n",
      "b7ce5de9980f: Preparing\n",
      "0796fbb63752: Preparing\n",
      "1233ef617acb: Preparing\n",
      "390ace10d575: Preparing\n",
      "c1b078f0e002: Preparing\n",
      "70720fcb790d: Preparing\n",
      "e05247f7d2f8: Preparing\n",
      "ab7c37becce8: Preparing\n",
      "5ccc1cf20429: Preparing\n",
      "b2d48dbbbef2: Preparing\n",
      "260b0b2ff58a: Preparing\n",
      "6babb56be259: Preparing\n",
      "610c8c70c225: Waiting\n",
      "11aaa1ad9bbe: Waiting\n",
      "c1540b4fd089: Waiting\n",
      "5be20e773bf8: Waiting\n",
      "f0aed3b553c7: Waiting\n",
      "e55c134eccb1: Waiting\n",
      "b3e660ff020a: Waiting\n",
      "1795fd5db4de: Waiting\n",
      "ab61683fbd20: Waiting\n",
      "117941aa2d3f: Waiting\n",
      "3a4c764c9a45: Waiting\n",
      "34db85e87fb0: Waiting\n",
      "782857218c62: Waiting\n",
      "dad41956ce77: Waiting\n",
      "0796fbb63752: Waiting\n",
      "195f2f019955: Waiting\n",
      "9546e4c87db8: Waiting\n",
      "1233ef617acb: Waiting\n",
      "78613865172b: Waiting\n",
      "390ace10d575: Waiting\n",
      "c1b078f0e002: Waiting\n",
      "97676aba1403: Waiting\n",
      "70720fcb790d: Waiting\n",
      "0fb4d6eba0b6: Waiting\n",
      "e05247f7d2f8: Waiting\n",
      "ab7c37becce8: Waiting\n",
      "e8b9f9e4195c: Waiting\n",
      "eb1f25078652: Waiting\n",
      "b7ce5de9980f: Waiting\n",
      "5ccc1cf20429: Waiting\n",
      "b2d48dbbbef2: Waiting\n",
      "260b0b2ff58a: Waiting\n",
      "6babb56be259: Waiting\n",
      "360afeadb83c: Layer already exists\n",
      "47eadc53848d: Mounted from tfx-oss-public/tfx\n",
      "610c8c70c225: Mounted from tfx-oss-public/tfx\n",
      "697060c05ee9: Pushed\n",
      "11aaa1ad9bbe: Mounted from tfx-oss-public/tfx\n",
      "5be20e773bf8: Mounted from tfx-oss-public/tfx\n",
      "c1540b4fd089: Mounted from tfx-oss-public/tfx\n",
      "f0aed3b553c7: Layer already exists\n",
      "e55c134eccb1: Mounted from tfx-oss-public/tfx\n",
      "1795fd5db4de: Mounted from tfx-oss-public/tfx\n",
      "b3e660ff020a: Mounted from tfx-oss-public/tfx\n",
      "29f0c0ff9749: Pushed\n",
      "ab61683fbd20: Layer already exists\n",
      "dad41956ce77: Mounted from tfx-oss-public/tfx\n",
      "f6ae1a92434a: Pushed\n",
      "34db85e87fb0: Layer already exists\n",
      "117941aa2d3f: Mounted from tfx-oss-public/tfx\n",
      "782857218c62: Mounted from tfx-oss-public/tfx\n",
      "3a4c764c9a45: Mounted from tfx-oss-public/tfx\n",
      "195f2f019955: Mounted from tfx-oss-public/tfx\n",
      "78613865172b: Mounted from tfx-oss-public/tfx\n",
      "9546e4c87db8: Mounted from tfx-oss-public/tfx\n",
      "e8b9f9e4195c: Layer already exists\n",
      "97676aba1403: Mounted from tfx-oss-public/tfx\n",
      "0fb4d6eba0b6: Mounted from tfx-oss-public/tfx\n",
      "0796fbb63752: Layer already exists\n",
      "eb1f25078652: Mounted from tfx-oss-public/tfx\n",
      "b7ce5de9980f: Mounted from tfx-oss-public/tfx\n",
      "1233ef617acb: Mounted from tfx-oss-public/tfx\n",
      "c1b078f0e002: Mounted from tfx-oss-public/tfx\n",
      "390ace10d575: Mounted from tfx-oss-public/tfx\n",
      "70720fcb790d: Mounted from tfx-oss-public/tfx\n",
      "e05247f7d2f8: Mounted from tfx-oss-public/tfx\n",
      "5ccc1cf20429: Layer already exists\n",
      "b2d48dbbbef2: Mounted from tfx-oss-public/tfx\n",
      "ab7c37becce8: Mounted from tfx-oss-public/tfx\n",
      "6babb56be259: Layer already exists\n",
      "260b0b2ff58a: Mounted from tfx-oss-public/tfx\n",
      "latest: digest: sha256:8a199d47c793a39322dd28b35d691077facca1236a13f3d0bacdfb20a3fa4d6f size: 8310\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                      STATUS\n",
      "50ccc38a-7852-416e-b039-e6e215e00740  2022-11-17T14:49:14+00:00  9M5S      gs://qwiklabs-asl-01-579c20dd4e24_cloudbuild/source/1668696554.129948-0ab50c6c1a5f4c3f91f62dc959625d37.tgz  gcr.io/qwiklabs-asl-01-579c20dd4e24/tfxcovertype (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout 15m --tag $TFX_IMAGE_URI ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile your pipeline code\n",
    "\n",
    "The following command will execute the `KubeflowV2DagRunner` that compiles the pipeline described in `pipeline.py` into a JSON representation consumable by Vertex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLI\n",
      "Compiling pipeline\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:absl:tensorflow_ranking is not available: No module named 'tensorflow_ranking'\n",
      "INFO:absl:tensorflow_text is not available: No module named 'tensorflow_text'\n",
      "INFO:absl:tensorflow_decision_forests is not available: No module named 'tensorflow_decision_forests'\n",
      "INFO:absl:struct2tensor is not available: No module named 'struct2tensor'\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "INFO:absl:tensorflow_text is not available: No module named 'tensorflow_text'\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "Pipeline tfxcovertype compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Your code here to compile the TFX Pipeline using the TFX CLI\n",
    "!tfx pipeline compile --engine vertex --pipeline_path runner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you should see a `{PIPELINE_NAME}.json` file appear in your current pipeline directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: deploy your pipeline on Vertex using the Vertex SDK\n",
    "\n",
    "Once you have the `{PIPELINE_NAME}.json` available, you can run the tfx pipeline on Vertex by launching a pipeline job using the `aiplatform` handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tfxcovertype-20221118080410?project=296524281444\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/296524281444/locations/us-central1/pipelineJobs/tfxcovertype-20221118080410 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [CsvExampleGen].; Job (project_id = qwiklabs-asl-01-579c20dd4e24, job_id = 2225263100548874240) is failed due to the above error.; Failed to handle the job: {project_number = 296524281444, job_id = 2225263100548874240}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3188/486322843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0menable_caching\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, sync)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     def submit(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [CsvExampleGen].; Job (project_id = qwiklabs-asl-01-579c20dd4e24, job_id = 2225263100548874240) is failed due to the above error.; Failed to handle the job: {project_number = 296524281444, job_id = 2225263100548874240}\"\n"
     ]
    }
   ],
   "source": [
    "# TODO: Your code here to use the vertex_ai sdk to deploy your\n",
    "# pipeline image to Vertex Pipelines.\n",
    "vertex_ai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "pipeline = vertex_ai.PipelineJob(\n",
    "    display_name=\"tfxcovertype4\",\n",
    "    template_path=PIPELINE_JSON,\n",
    "    enable_caching=False,\n",
    ")\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you learned how to build and deploy a TFX pipeline with the TFX CLI and then update, build and deploy a new pipeline with automatic hyperparameter tuning. You practiced triggered continuous pipeline runs using the TFX CLI as well as the Kubeflow Pipelines UI.\n",
    "\n",
    "\n",
    "In the next lab, you will construct a Cloud Build CI/CD workflow that further automates the building and deployment of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "            http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
